{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46cfc396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 25)                19625     \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 15)                390       \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 10)                160       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,175\n",
      "Trainable params: 20,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8208\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7743\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5309\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3967\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3000\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2470\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2176\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1916\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1803\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1658\n",
      "\n",
      "\n",
      "Enter the number of pictures 1-100 to test5\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "number probabilities from 0 to 9: \n",
      "[[3.1012161e-20 8.5854461e-09 1.8152265e-06 1.1817736e-03 2.2880737e-11\n",
      "  6.8792428e-06 7.4715050e-29 9.9880958e-01 4.6760803e-08 1.3022055e-09]]\n",
      "actual number: 7\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "number probabilities from 0 to 9: \n",
      "[[1.07549955e-13 8.29646183e-08 9.77233648e-01 2.27641966e-02\n",
      "  1.17146139e-16 1.07755261e-06 5.05193543e-12 9.84001417e-07\n",
      "  2.08760653e-09 1.03928377e-23]]\n",
      "actual number: 2\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "number probabilities from 0 to 9: \n",
      "[[5.1714468e-09 9.9569964e-01 2.6006016e-04 8.6103420e-05 1.2154873e-05\n",
      "  8.3472914e-05 1.1731894e-03 1.2088893e-04 2.5557172e-03 8.8859288e-06]]\n",
      "actual number: 1\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "number probabilities from 0 to 9: \n",
      "[[9.9947685e-01 1.3399854e-12 1.5374584e-05 5.8984233e-06 9.2945223e-14\n",
      "  3.7152688e-05 4.5566139e-04 6.4136539e-06 2.7215297e-06 1.1102133e-12]]\n",
      "actual number: 0\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "number probabilities from 0 to 9: \n",
      "[[7.4795503e-06 9.7878779e-05 4.7312179e-03 7.4887153e-04 9.8230767e-01\n",
      "  1.0979988e-03 8.7655219e-04 7.0046075e-03 2.0635313e-04 2.9213137e-03]]\n",
      "actual number: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#We are going to make a neural network model to identify the handwritten digits 0 to 9.\n",
    "y = [] # labels\n",
    "X = [] # features\n",
    "traincsv = open(\"mnist_train.csv\",\"r\") \n",
    "reader = csv.reader(traincsv)\n",
    "count = 0\n",
    "for row in reader:\n",
    "    if count!= 0:\n",
    "        y.append(row[0])\n",
    "        X.append(row[1:len(row)])\n",
    "    count+=1\n",
    "for i in range(len(y)):\n",
    "    y[i] = float(y[i])\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(X[i])):\n",
    "        X[i][j] = float(X[i][j])\n",
    "\n",
    "#our neural network will have three layers.\n",
    "#Each unit in each dense layer will recieve input X and calculate z = wx+b\n",
    "    #layer 1 and 2 output regularized linear activations, given by max(0,z)\n",
    "#layer 2 outputs a softmax activation, where each category (0-9) has a unit, which computes z = wx+b,\n",
    "    #and the activation for each unit is given by a[i]=e**(z_i)/(e**(z_i)+e**(z_i+1)+e**(z_i+2)...+e**(z_i+9)\n",
    "model = Sequential([\n",
    "        tf.keras.Input(shape=(784,)),\n",
    "        Dense(units = 25, activation = \"relu\", name=\"layer1\"),\n",
    "        Dense(units = 15, activation = \"relu\", name=\"layer2\"),\n",
    "        Dense(units = 10, activation = \"softmax\", name=\"layer3\")\n",
    "        ])\n",
    "\n",
    "#sparce categorical crossentropy means that we are choosing between a set number of categories (0-9).\n",
    "#the loss function for softmax is given by J = -log(a[i]) {y=a[i]}\n",
    "#the loss function for ReLU is given by J = 1/m * the sum of all (f_wb_x[i]-y)**2, which is the mean squared error.\n",
    "#the \"adam\" optimizer stands for adaptive moment estimation, which essentially speeds up gradient descent\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.summary() #this will display the info about our model\n",
    "\n",
    "model.fit(X,y,epochs = 10) #notice how the loss is decreasing as we train.\n",
    "                           #gradient descent is to minimize w,b, with w = w - alpha * dJ_dw, and b = b - alpha * dJ_db\n",
    "                               #where dJ_dw = 1/m * the sum of all x[i]*(f_wb_x[i]-y)**2\n",
    "                               #and dJ_db = 1/m * the sum of all (f_wb_x[i]-y)**2\n",
    "                           #an epoch is one pass over all the training data\n",
    "\n",
    "test_y = [] # correct identifications\n",
    "test_X = [] # input image\n",
    "testcsv = open(\"mnist_test.csv\",\"r\")\n",
    "reader = csv.reader(testcsv)\n",
    "count = 0\n",
    "for row in reader:\n",
    "    if count!= 0:\n",
    "        test_y.append(row[0])\n",
    "        test_X.append(row[1:len(row)])\n",
    "    count+=1\n",
    "for i in range(len(test_y)):\n",
    "    test_y[i] = float(test_y[i])\n",
    "for i in range(len(test_X)):\n",
    "    for j in range(len(test_X[i])):\n",
    "        test_X[i][j] = float(test_X[i][j])\n",
    "test_X = tf.convert_to_tensor(test_X)\n",
    "userInput = input(\"\\n\\nEnter the number of pictures 1-100 to test\")\n",
    "for i in range(int(userInput)):\n",
    "    prediction = model.predict(test_X[i].reshape(1,784))\n",
    "    print(\"number probabilities from 0 to 9: \\n\" +str(prediction)) #notice how the correct number is around 99%\n",
    "    print(\"actual number: \" +str(int(test_y[i]))+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
